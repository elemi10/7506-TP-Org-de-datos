{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Tp2_7506.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elemi10/7506-TP-Org-de-datos/blob/elemi10-7506-Trabajo-Practico-2/Tp2_7506.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrL_RUeZO7P0",
        "colab_type": "text"
      },
      "source": [
        "# Tp-2 Org de datos( FIUBA)\n",
        "\n",
        "\n",
        "    \n",
        "      \n",
        "      \n",
        "      \n",
        "***\n",
        "\n",
        "***\n",
        "### Importacion de librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywvX4yltPf1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#IMPORT FILES FROM DRIVE INTO GOOGLE-COLAB:\n",
        "\n",
        "#STEP-1: Import Libraries\n",
        "\n",
        "# Code to read csv file into colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXWPAkrDPogU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STEP-2: Autheticate E-Mail ID\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E1JJnZjP9eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#STEP-3: Get File from Drive using file-ID\n",
        "\n",
        "#2.1 Get the file\n",
        "downloaded = drive.CreateFile({'id':'1RAGDjlzJ6spO5Sq8_x3UTIvxLhKAUBEt'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('train.csv') \n",
        "\n",
        "downloaded1 = drive.CreateFile({'id':'17pAgG9oJRK1bAFWRKkp96__zicG6yUmy'}) # replace the id with id of file you want to access\n",
        "downloaded1.GetContentFile('test.csv') \n",
        "\n",
        "downloaded2 = drive.CreateFile({'id':'1u8v51BT7FZggIRD-eo0dQno--0wlxIhA'}) # replace the id with id of file you want to access\n",
        "downloaded2.GetContentFile('sample_submission.csv') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x7YlhZuO7P2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "29262ba7-c07e-41e6-f7ed-0a378c4197d4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download(\"popular\")\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split,cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.corpus import stopwords \n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8yrHmRMO7QE",
        "colab_type": "text"
      },
      "source": [
        "### Archivos necesarios"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poifwBbpO7QI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c79a6450-bdaf-49c3-8f4c-c35cc8d6ee90"
      },
      "source": [
        "train=pd.read_csv(r\"train.csv\")\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8DK7J68O7QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6996054e-6141-4f8a-9e0e-7cda9de7a354"
      },
      "source": [
        "test=pd.read_csv(r\"test.csv\")\n",
        "test.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword location                                               text\n",
              "3258  10861     NaN      NaN  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...\n",
              "3259  10865     NaN      NaN  Storm in RI worse than last hurricane. My city...\n",
              "3260  10868     NaN      NaN  Green Line derailment in Chicago http://t.co/U...\n",
              "3261  10874     NaN      NaN  MEG issues Hazardous Weather Outlook (HWO) htt...\n",
              "3262  10875     NaN      NaN  #CityofCalgary has activated its Municipal Eme..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqWi9v0_O7Qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7a63e09d-d67c-4b08-f46f-df73be78cbab"
      },
      "source": [
        "sample_submission=pd.read_csv(r\"sample_submission.csv\")\n",
        "sample_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  target\n",
              "0   0       0\n",
              "1   2       0\n",
              "2   3       0\n",
              "3   9       0\n",
              "4  11       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZNM5WHLO7Qr",
        "colab_type": "text"
      },
      "source": [
        "## Generacion de algunas variables y nuevos DF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuAiGp2SO7Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text=train.text\n",
        "train_target=train.target\n",
        "test_text=test.text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEbWDZPGO7Q3",
        "colab_type": "text"
      },
      "source": [
        "##### Datasets que con nulos rellenados como 'none'\n",
        "****\n",
        "* Despues probar rellenando con 'nokeyword','nolocation'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj-nbqGAO7Q5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "a3abb5b0-2629-45a4-8e03-80b7eaad5eb5"
      },
      "source": [
        "train_na=train.fillna(value='none')\n",
        "test_na=test.fillna(value='none')\n",
        "train_na['keyword+text']=train_na.text+''+train_na.keyword\n",
        "test_na['keyword+text']=test_na.text+''+test_na.keyword\n",
        "train_na['Caracteres']=train_na.text.str.len()\n",
        "test_na['Caracteres']=test_na.text.str.len()\n",
        "train_na.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>keyword+text</th>\n",
              "      <th>Caracteres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>94</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... Caracteres\n",
              "7608  10869  ...         83\n",
              "7609  10870  ...        125\n",
              "7610  10871  ...         65\n",
              "7611  10872  ...        137\n",
              "7612  10873  ...         94\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zu-MY-wO7RD",
        "colab_type": "text"
      },
      "source": [
        "### Clasificadores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSxpVUMSO7RE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Establecemos a la regresion logistica como clasificador\n",
        "# Arbol como clasificador\n",
        "cls=LogisticRegression()\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "gbc = GradientBoostingClassifier(random_state=0)\n",
        "rfc=RandomForestClassifier(random_state=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGqsQM02O7RJ",
        "colab_type": "text"
      },
      "source": [
        "# *MODELOS*\n",
        " \n",
        "  \n",
        "   \n",
        "    \n",
        "     \n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-TCt7nNO7RK",
        "colab_type": "text"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra20CeGaO7RM",
        "colab_type": "text"
      },
      "source": [
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPdxaORxO7RO",
        "colab_type": "text"
      },
      "source": [
        "######   **Modelo 0**: Simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79p7sasOO7RQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "ad89bc2e-3ac2-4f3b-c13e-ccba32bfbd81"
      },
      "source": [
        "#Vectorizer, simple \n",
        "vectorizer=CountVectorizer()\n",
        "vectorizer.fit(train_text)\n",
        "X_train=vectorizer.transform(train_text)\n",
        "X_test=vectorizer.transform(test_text)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x21637 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 111497 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH6N9OteO7RX",
        "colab_type": "text"
      },
      "source": [
        "###### *Modelo 1*: Agregando stopwords y eliminando caracteres tiles y ese tipo de cosas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FbAMTu3O7RY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "08e05499-d59d-492b-f891-fe46c097cb66"
      },
      "source": [
        "#Vectorizer1, agregando stopwords y distintos n_grams\n",
        "stopwords=stopwords.words('english')\n",
        "vectorizer1=CountVectorizer(strip_accents='ascii',stop_words=stopwords,ngram_range=(1,5),max_df=0.95)\n",
        "vectorizer1.fit(train_text)\n",
        "X_train1=vectorizer1.transform(train_text)\n",
        "X_test1=vectorizer1.transform(test_text)\n",
        "X_train1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x232480 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 344172 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3X5rmD3O7Rf",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 2: Uso de TF-IDF "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UauxkUhOO7Rh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2ee2f175-4a8d-4586-f99a-41d31c216b22"
      },
      "source": [
        "#Vectorizer2, usando TF-IDF\n",
        "vectorizer2=TfidfVectorizer()\n",
        "vectorizer2.fit(train_text)\n",
        "X_train2=vectorizer2.transform(train_text)\n",
        "X_test2=vectorizer2.transform(test_text)\n",
        "X_train2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x21637 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 111497 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdt5jPC9O7Ro",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 3: Uso de TF-IDF,sacando acentos y analizando varios n_grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R3vhrcyO7Rq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "65e861e2-3ef5-404b-ff10-ebb2631ab5b7"
      },
      "source": [
        "# Vectorizer3, usando TF-iDF, sacando acentos y agreando n_grams\n",
        "max_n3=15\n",
        "vectorizer3=TfidfVectorizer(strip_accents='ascii',ngram_range=(1,max_n3),)\n",
        "vectorizer3.fit(train_text)\n",
        "X_train3=vectorizer3.transform(train_text)\n",
        "X_test3=vectorizer3.transform(test_text)\n",
        "X_train3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x769185 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1004105 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeRmWwc_O7Ry",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 4: Inclusion de Lemmatizador, NO incluye uso de TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjmOKMBzO7Rz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "590e1e9b-737e-44f7-e1f4-13e5faed9e21"
      },
      "source": [
        "# Vectorizer4\n",
        "# Creamos un lemmatizador \n",
        "class LemmaTokenizer:\n",
        "    def __init__(self):\n",
        "        self.wnl = WordNetLemmatizer()\n",
        "    def __call__(self, doc):\n",
        "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]\n",
        "\n",
        "vectorizer4=CountVectorizer(tokenizer=LemmaTokenizer())\n",
        "vectorizer4.fit(train_text)\n",
        "X_train4=vectorizer4.transform(train_text)\n",
        "X_test4=vectorizer4.transform(test_text)\n",
        "X_train4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x22003 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 128166 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq2w0mjiO7R5",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 5( mejores resultados):  \n",
        "- Uso de columna keyword + text\n",
        "- Lemmatizador"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqzscyKDO7R6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text_y_keyword=train_na['keyword+text']\n",
        "test_text_y_keyword=test_na['keyword+text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTcDe22cO7SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilizo keyword en mi analisis\n",
        "vectorizer5=CountVectorizer(tokenizer=LemmaTokenizer())\n",
        "vectorizer5.fit(train_text_y_keyword)\n",
        "X_train5=vectorizer5.transform(train_text_y_keyword)\n",
        "X_test5=vectorizer5.transform(test_text_y_keyword)\n",
        "X_train5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MgB1RI-O7SI",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 6: Utilizo keyword en mi analisis y TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cd3H5dUTO7SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "97c14061-144b-4f38-8884-edb9fee88e7b"
      },
      "source": [
        "# Utilizo keyword en mi analisis y TF-IDF\n",
        "vectorizer6=TfidfVectorizer(tokenizer=LemmaTokenizer())\n",
        "vectorizer6.fit(train_text_y_keyword)\n",
        "X_train6=vectorizer6.transform(train_text_y_keyword)\n",
        "X_test6=vectorizer6.transform(test_text_y_keyword)\n",
        "X_train6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x24172 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 130285 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwID8NvzO7SO",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 7: Inclusion de columna location"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx5M--hKO7SQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agregamos columna location \n",
        "train_text_keyword_location=train_na.text+''+train_na.keyword+''+train_na.location\n",
        "test_text_keyword_location=test_na.text+''+test_na.keyword+''+test_na.location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPtdyA7ZO7SY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "d8c259b9-3483-4c5b-cb23-f05801d2f583"
      },
      "source": [
        "vectorizer7=CountVectorizer(tokenizer=LemmaTokenizer())\n",
        "vectorizer7.fit(train_text_keyword_location)\n",
        "X_train7=vectorizer7.transform(train_text_keyword_location)\n",
        "X_test7=vectorizer7.transform(test_text_keyword_location)\n",
        "X_train7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<7613x26489 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 138938 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajSBLrnzO7Se",
        "colab_type": "text"
      },
      "source": [
        "###### Modelo 8: Utilizamos funcion train_test_split.....\n",
        "- No tiene ningun tipo de mejora al modelo, es solo para probar, se puede utlizar para calcular el Score en lugar de hacer sub\n",
        "- Despues se generaliza para todo el set de entrenamiento y se predice set de test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uoi67poO7Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train_na['keyword+text']\n",
        "y=train_na['target']\n",
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, test_size=0.20, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3g3xgmzO7Sm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "cba578da-ecea-46c1-e7bb-036965640a8d"
      },
      "source": [
        "vectorizer8=CountVectorizer(strip_accents='ascii',tokenizer=LemmaTokenizer())\n",
        "vectorizer8.fit(X_train_)\n",
        "X_train8=vectorizer8.transform(X_train_)\n",
        "X_test8=vectorizer8.transform(X_test_)\n",
        "X_train8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<6090x20596 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 104553 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nug83Y-CO7Sr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f6a583f0-9ae6-4128-974b-9f69972a253d"
      },
      "source": [
        "## Calculamos Score con este metodo, sin hacer cross validation\n",
        "cls.fit(X_train8,y_train_)\n",
        "prediction0=cls.predict(X_test8)\n",
        "print(f1_score(y_test_,prediction0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7618243243243243\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqOQp9aeO7Sx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "bbb3b478-62ca-4178-9241-6aa9f9241358"
      },
      "source": [
        "### Progabmos el score con algunos de los clasificadores\n",
        "gbc.fit(X_train8,y_train_)\n",
        "cls.fit(X_train8,y_train_)\n",
        "prediction0=cls.predict(X_test8)\n",
        "prediction1=gbc.predict(X_test8)\n",
        "print('RL: {}'.format(f1_score(y_test_,prediction0)))\n",
        "print('GBC: {}'.format(f1_score(y_test_,prediction1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RL: 0.7618243243243243\n",
            "GBC: 0.6611570247933884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P87TFsSO7S6",
        "colab_type": "text"
      },
      "source": [
        "## Clasificador propio\n",
        "- Lemmatizador\n",
        "- One-hot\n",
        "- Cuenta cantidad de caracteres"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tyCwppO7S8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lemmatizer(BaseEstimator):\n",
        "    def __init__(self):\n",
        "        self.l = WordNetLemmatizer()\n",
        "        \n",
        "    def fit(self, x, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, x):\n",
        "        x = map(lambda r:  ' '.join([self.l.lemmatize(i.lower()) for i in r.split()]), x)\n",
        "        x = np.array(list(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1DeXZnJO7TA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def length_text(x):\n",
        "    return np.array(x.str.len()).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12xhBXA9O7TL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm=Lemmatizer()\n",
        "vec=CountVectorizer()\n",
        "lr=LogisticRegression()\n",
        "clasificador=Pipeline([\n",
        "    ('features',FeatureUnion([\n",
        "        ('text',Pipeline([\n",
        "            ('lm',lm),\n",
        "            ('vec',vec)])),\n",
        "        ('lenght',Pipeline([\n",
        "            ('car',FunctionTransformer(length_text,validate=False))\n",
        "        ]))\n",
        "    ])),\n",
        "    ('lr',lr)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0PcawPNO7TR",
        "colab_type": "text"
      },
      "source": [
        "- *Cross validation del nuevo clasificador*\n",
        "- *El texto es text+keyword*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3LmFZMdO7TT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "05c7197c-a027-464b-c206-0ebf98493822"
      },
      "source": [
        "cross_val_score(estimator=clasificador,X=train_text_y_keyword,y=train_na.target,cv=6,scoring='f1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.61366181, 0.59171598, 0.59357278, 0.52380952, 0.6471183 ,\n",
              "       0.72643253])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ziyLM_wO7Tc",
        "colab_type": "text"
      },
      "source": [
        "* Calculamos f1 para el nuevo clasificador  (Sigue usando el df spliteado)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r36updUhO7Ti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "c625bca8-7ec8-4b47-a177-410268094dc0"
      },
      "source": [
        "clasificador.fit(X_train_,y_train_)\n",
        "clas_predict=clasificador.predict(X_test_)\n",
        "f1_score(clas_predict,y_test_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7350993377483444"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGkLIZjrO7Tv",
        "colab_type": "text"
      },
      "source": [
        "* Generalizamos para todo el set de train, asi tiene mayor corpus\n",
        "* Hacemos submit con nuevo clasificador\n",
        "* (No tiene el mejor resultado en kaggle, seria bueno hacer un grid search)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yoikuSlO7Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ahora hacemos que utilice todo el dataset, asi tiene mayor corpus\n",
        "clasificador.fit(train_text_y_keyword,train_na.target)\n",
        "sample_submission['target']=clasificador.predict(test_text_y_keyword)\n",
        "sample_submission.to_csv('sub_9(class).csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnyZBXmvO7T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA9FYiV7O7UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WbP2_CKO7UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoc0I-vEO7UP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U139ncXsO7Ub",
        "colab_type": "code",
        "colab": {},
        "outputId": "e6f7e5f1-a84d-4d58-b60f-f350b51f31c0"
      },
      "source": [
        "# Por curisidad \n",
        "print(X_train[0].todense())\n",
        "print(X_train1[0].todense())\n",
        "print(X_train2[0].todense())\n",
        "print(X_train3[0].todense())\n",
        "print(X_train4[0].todense())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]]\n",
            "[[0 0 0 ... 0 0 0]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0. 0. 0. ... 0. 0. 0.]]\n",
            "[[0 1 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4LjE0-4O7Ui",
        "colab_type": "code",
        "colab": {},
        "outputId": "c92f637f-b935-4ae7-d5e6-b8df2cdfc6bd"
      },
      "source": [
        "# Establecemos un score, usamos f1 que es el utilizado en competencia\n",
        "score=model_selection.cross_val_score(cls,X_train,train.target,cv=10,scoring='f1')\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.62956522, 0.56218058, 0.51779935, 0.5152    , 0.5800317 ,\n",
              "       0.6048    , 0.58983051, 0.52532833, 0.70788253, 0.72941176])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh_ru-ZVO7Uo",
        "colab_type": "code",
        "colab": {},
        "outputId": "722a419b-001c-42bf-b3e9-b309cdee8acd"
      },
      "source": [
        "score1=model_selection.cross_val_score(cls,X_train1,train.target,cv=10,scoring='f1')\n",
        "score1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.58113208, 0.47524752, 0.46704331, 0.53214286, 0.49446494,\n",
              "       0.57692308, 0.55893536, 0.42173913, 0.65964912, 0.72758037])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6zFHhk3O7Uu",
        "colab_type": "code",
        "colab": {},
        "outputId": "d79835c7-f086-4cb7-af66-c5a00f7f9a0f"
      },
      "source": [
        "score2=model_selection.cross_val_score(cls,X_train2,train.target,cv=10,scoring='f1')\n",
        "score2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.64084507, 0.62239089, 0.56624319, 0.5915493 , 0.61217391,\n",
              "       0.62650602, 0.61202186, 0.57685009, 0.69505963, 0.74598071])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgo5zAC3O7Uy",
        "colab_type": "code",
        "colab": {},
        "outputId": "c1ae5fcb-da1a-404c-ee2b-3b64c6b6d9e5"
      },
      "source": [
        "score3=model_selection.cross_val_score(cls,X_train3,train.target,cv=10,scoring='f1')\n",
        "score3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2915601 , 0.24415584, 0.28426396, 0.25      , 0.21705426,\n",
              "       0.22942643, 0.19672131, 0.29648241, 0.31862745, 0.46052632])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktasy-ZyO7U2",
        "colab_type": "code",
        "colab": {},
        "outputId": "43c4375b-860a-42df-aa74-f94f7e30e5c3"
      },
      "source": [
        "score4=model_selection.cross_val_score(cls,X_train4,train.target,cv=10,scoring='f1')\n",
        "score4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.64248705, 0.53767123, 0.53269537, 0.53125   , 0.609375  ,\n",
              "       0.57463884, 0.6013289 , 0.53141831, 0.72977099, 0.73669065])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPtATF5nO7U7",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1394889-5c9d-4e39-da37-3ab3d5d892ec"
      },
      "source": [
        "score4_=model_selection.cross_val_score(clf,X_train4,train.target,cv=10,scoring='f1')\n",
        "score4_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.52886406, 0.57189542, 0.47284345, 0.46381579, 0.54205607,\n",
              "       0.52365931, 0.53924915, 0.53003534, 0.59810127, 0.65486726])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQL3f4m2O7VB",
        "colab_type": "code",
        "colab": {},
        "outputId": "4e65e69b-aacf-4a7d-c557-e9f0f444a3f6"
      },
      "source": [
        "score5=model_selection.cross_val_score(cls,X_train5,train_na.target,cv=6,scoring='f1')\n",
        "score5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.65005417, 0.57838364, 0.59558117, 0.54929577, 0.69147894,\n",
              "       0.74649205])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ7nhA2cO7VF",
        "colab_type": "code",
        "colab": {},
        "outputId": "03d09dd9-9b5e-4c6a-b9fe-b31eea5e4561"
      },
      "source": [
        "score5_=model_selection.cross_val_score(clf,X_train5,train_na.target,cv=10,scoring='f1')\n",
        "score5_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.54243542, 0.53505007, 0.48717949, 0.48648649, 0.56835637,\n",
              "       0.55054432, 0.58897638, 0.58762887, 0.66049383, 0.62208398])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPFFSpW1O7VJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score5_gbc=score5_=model_selection.cross_val_score(gbc,X_train5,train_na.target,cv=10,scoring='f1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLo2qR96O7VO",
        "colab_type": "code",
        "colab": {},
        "outputId": "6dd468fe-fc8e-4bdf-b3be-eff581fd9d44"
      },
      "source": [
        "score5_gbc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.56214149, 0.5754717 , 0.35135135, 0.56766917, 0.48405253,\n",
              "       0.54888508, 0.46990291, 0.57509158, 0.65734266, 0.65326633])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvbfLnFbO7VU",
        "colab_type": "code",
        "colab": {},
        "outputId": "cc7cc526-db9e-4c02-cec3-b7aeb717ac48"
      },
      "source": [
        "score5_rfc=model_selection.cross_val_score(rfc,X_train5,train_na.target,cv=10,scoring='f1')\n",
        "score5_rfc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.53927813, 0.48888889, 0.42352941, 0.41509434, 0.51737452,\n",
              "       0.46095238, 0.49173554, 0.33103448, 0.5300207 , 0.64631957])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt38BJy6O7VX",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0caa4d9-3412-4dbb-ec83-792a018640b0"
      },
      "source": [
        "score6=model_selection.cross_val_score(cls,X_train6,train_na.target,cv=10,scoring='f1')\n",
        "score6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66181818, 0.6369863 , 0.5659051 , 0.59375   , 0.63032368,\n",
              "       0.60207612, 0.64027539, 0.55491329, 0.72361809, 0.75      ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWhNZD0PO7Va",
        "colab_type": "code",
        "colab": {},
        "outputId": "76fd02cb-a746-4b9c-e58a-243755421f6b"
      },
      "source": [
        "score7=model_selection.cross_val_score(cls,X_train7,train_na.target,cv=8,scoring='f1')\n",
        "score7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\jinci\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68802228, 0.57281553, 0.59055118, 0.60947503, 0.57364341,\n",
              "       0.639201  , 0.64054054, 0.73293413])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfbKnW2JO7Vg",
        "colab_type": "code",
        "colab": {},
        "outputId": "87a2799b-6281-47fb-93e8-6d225083f99c"
      },
      "source": [
        "score7>score5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXBhUl9SO7Vl",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d7c1028-8755-4c94-cdd6-34255b2f9107"
      },
      "source": [
        "score5>score6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un3qTHO0O7Vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moxTQEbrO7Vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6Et6jBzO7V_",
        "colab_type": "code",
        "colab": {},
        "outputId": "59c07221-d8da-49c5-861d-9f49f36053f5"
      },
      "source": [
        "clf.fit(X_train5,train_na.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
              "                       max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort=False,\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpBaP1YtO7WD",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f044737-08ce-453f-a3aa-1715714b51b3"
      },
      "source": [
        "#Ajusto para el 5to modelo\n",
        "cls.fit(X_train7,train_na.target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8ssX892O7WJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsYJ_TfVO7WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# De nuevo, trabajo con el 4to modelo\n",
        "sample_submission['target']=cls.predict(X_test7)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAtDv_THO7WR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creo el csv con el cuarto modelo\n",
        "sample_submission.to_csv('sub8.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PISsqrx2O7WT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}