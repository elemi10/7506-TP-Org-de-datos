{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP1 - 7506 Org Datos.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elemi10/7506-TP-Org-de-datos/blob/7506-Trabajo-Practico-1/TP1_7506_Org_Datos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7he79fqwwT-O",
        "colab_type": "text"
      },
      "source": [
        "# **TP1 - Real or Not?**\n",
        "\n",
        "###  **Análisis exploratorio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZEYitYMwTjL",
        "colab_type": "text"
      },
      "source": [
        "![Banner_TP1.png](https://drive.google.com/uc?id=1BPA2RF1SDm9bTs1xZfVUa1VQn932E3wr)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_hz5faWjRJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zMCT9MSjSHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji2daQ4wkRla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':'1RAGDjlzJ6spO5Sq8_x3UTIvxLhKAUBEt'}) # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('train.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLkrdZyidZU",
        "colab_type": "text"
      },
      "source": [
        "### Importamos **Librerias**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61knxy6eiYZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "import datetime as dt\n",
        "import scipy as sp\n",
        "#from sklearn.cross_validation import train_test_split -- no levanta\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (16,9)\n",
        "plt.style.use('default') # mejoramos esteticamente un poco los gráficos en matplotlib\n",
        "sns.set(style='whitegrid') # seteando tipo de grid en seaborn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#from sklearn.metrics import confusion_matrix\n",
        "#from sklearn.naive_bayes import GaussianNB\n",
        "#from sklearn.metrics import classification_report\n",
        "#from sklearn.feature_selection import SelectKBest\n",
        "#from sklearn.cross_validation import train_test_split --> No levanta el feature de la libreria"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8FIwfsGi8ZC",
        "colab_type": "text"
      },
      "source": [
        "### Levantramos el archivo **train.csv**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QtvttVli06t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(r'train.csv', usecols=['keyword','location','text','target']) \n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9iCOxiyujyS",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXRNZx1alA94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verifico que no haya instancias nulas o filas completas nulas\n",
        "df_train=df_train.dropna(how=\"all\")\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOvXdYdllC3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalizo el dataframe los registros NaN con texto\n",
        "df_train=df_train.fillna({'keyword': 'sin keyword',\\\n",
        "                   'location': 'sin location'})\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0LlgXdAlHEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eliminamos los tweets duplicados considerando que su cantidad no tiene impacto en el análisis.\n",
        "df_train=df_train.drop_duplicates('text')\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb9-OneNlV2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verificamos la existencia de valores nulos\n",
        "df_train.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDEGwDq3t73p",
        "colab_type": "text"
      },
      "source": [
        "**→ Creamos una serie que hace el conteo de la cant de caracteres del tweet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d_yYt2jq2Jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creo una columna con el cálculo de las palabras que tiene la columna 'text' y la llamo 'caracteres_tweet'. \n",
        "# Despues consulto con un head()\n",
        "df_train['caracteres_tweet']=df_train['text'].str.len()\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_MtY9MXuFLm",
        "colab_type": "text"
      },
      "source": [
        "### Cálculo de **estadísticas básicas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwco_I9flXqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculamos unas estadisticas basicas\n",
        "df_train.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF6Nqw2cqr9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Calculo el promedio y lo asigno a la variable 'df_short_mean'\n",
        "df_train_mean=np.round(df_train['caracteres_tweet'].mean(), decimals=2)\n",
        "df_train_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhQeLID8rERy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculo la mediana, para tener presente como impacta max() y min() en la distribución\n",
        "df_train_median=np.round(df_train['caracteres_tweet'].median(), decimals=2)\n",
        "df_train_median"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWygc3Stlq_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cuento total de tweets analizados\n",
        "total_tweets=len(df_train)\n",
        "total_tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC_QJl2ElsDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verifico cuantos son verdaderos\n",
        "tweets_verdaderos=(df_train['target']==1).sum()\n",
        "tweets_verdaderos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GRb5WQqlv_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verifico cuantos son fakes\n",
        "tweets_falsos=(df_train['target']==0).sum()\n",
        "tweets_falsos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ2uydMUmFaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculo la probabilidad (casos favorables/sobre casos posibles) → en este casos es equivalente .mean()\n",
        "probabilidad_tweet_verdadero = np.round((tweets_verdaderos)/(total_tweets),decimals=5)\n",
        "probabilidad_tweet_verdadero"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOPpR4_CmHv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculo la probabilidad (casos favorables/sobre casos posibles) → en este casos es equivalente .mean()\n",
        "probabilidad_tweet_falso = np.round((tweets_falsos)/(total_tweets),decimals=2)\n",
        "probabilidad_tweet_falso"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EaWbBRNmjIV",
        "colab_type": "text"
      },
      "source": [
        "**→ Asignación de variables para cálculos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVWB5x-nmcCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Asigno a variables para que se puedan operar alfabéticamente\n",
        "tweets_verdaderos=df_train['target']==1\n",
        "tweets_verdaderos.head()\n",
        "# Verifico cantidad de tweets verdaderos\n",
        "tweets_verdaderos.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjG6uIQ9soGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aplico la misma acción para tweets fakes\n",
        "# verifico cantidad de tweets fakes\n",
        "tweets_fake=df_train['target']==0\n",
        "tweets_fake.head()\n",
        "tweets_fake.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L3VGVNbmQud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Asigno a la variable 'tweets_mayor_promedio', los tweets que tienen un promedio en cant de registros > Promedio (de caracteres de tweets del DF)\n",
        "# Me va a servir para ver mas adelante como es su distribución\n",
        "tweets_mayor_promedio=df_train['caracteres_tweet']>=(df_train_mean)\n",
        "# Hago un .head() para verificar para despues hacer la suma de tweets con una cant de caracteres mayor al promedio\n",
        "print(tweets_mayor_promedio.head())\n",
        "tweets_mayor_promedio.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BzKcwdBs74g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lo mismo que el apartado anterior, con la diferencia que traigo en la variable 'tweets_menor_promedio' \n",
        "# aquellos registros que son menor al promedio\n",
        "tweets_menor_promedio=df_train['caracteres_tweet']<(df_train_mean)\n",
        "tweets_menor_promedio.sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A7T1m9fvfUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Por un tema de comodidad, creo una nueva columna con la referencia al valor booleano de la variable 'target'.\n",
        "# 0=tweet falso | 1=tweet verdadero\n",
        "df_train['tweet_type']=np.where(df_train['target']==1,\"tweet verdadero\",\"tweet falso\")\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z9gXmPevtnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reverifico\n",
        "pd.value_counts(df_train['tweet_type'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXAQy5OyvyWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Armo una tabla de frecuencia de las variables\n",
        "100*df_train['tweet_type'].value_counts()/len(df_train['tweet_type'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SBbRp_fv2Aw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Agrego una categoría para agrupar por promedio\n",
        "df_train['avg_category']=np.where(df_train['caracteres_tweet']>=(df_train_mean)\\\n",
        "                                  ,\"tw w/characts.above AVG ocurrs.\",\"tw w/characts.below AVG ocurrs\") \n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXGL_QZBwH_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Relaciono las variables con una tabla de contingencia (%)\n",
        "pd.crosstab(index=df_train['tweet_type'], columns=df_train['avg_category'], \\\n",
        "            margins=True).apply(lambda x:x/len(df_train)*100,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOrIhLYkxwpi",
        "colab_type": "text"
      },
      "source": [
        "### Gráfico **Overlaid Density Plots** [Distribución]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOhVWAzsxn3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grafico de tabla de contingencia de los tweets falsos vs tweets v en funcion del promedio de caracteres\n",
        "graph_distrb=sns.kdeplot(df_train[df_train['tweet_type']==\"tweet verdadero\"]['caracteres_tweet'],\\\n",
        "                         color=\"orange\", label=\"distribution on TRUE avg tweets\", shade=True)\n",
        "\n",
        "graph_distrb=sns.kdeplot(df_train[df_train['tweet_type']==\"tweet falso\"]['caracteres_tweet'], \\\n",
        "                         color=\"blue\", label=\"distribution on FAKE avg tweets\", shade=True)\n",
        "\n",
        "graph_distrb.set_title(\"avg tweets characters Distribution\", fontsize=18)\n",
        "graph_distrb.set_ylabel(\"Densidad\", fontsize=18)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9N75GarzeJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bhMB0YIwfNw",
        "colab_type": "text"
      },
      "source": [
        "### **Análisis & tokenización**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8_xHK_VwlSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Función de tokenización\n",
        "import string\n",
        "punctuation = set(string.punctuation)\n",
        "\n",
        "def tokenize(sentence):\n",
        "    tokens = []\n",
        "    for token in sentence.split():\n",
        "        new_token = []\n",
        "        for character in token:\n",
        "            if character not in punctuation:\n",
        "                new_token.append(character.lower())\n",
        "        if new_token:\n",
        "            tokens.append(\"\".join(new_token))\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArzzacYN81ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creo la serie 'text_vector'\n",
        "df_train['text_vector']=df_train['text'].apply(tokenize)\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaBYYZ7T8_FC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verifico integridad de DF\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E8x1l769CIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Descargo e importo lista de stopwords para filtrar\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNiZDXDG9vDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.fileids()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bT2hiea9ySY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Asigno en la variable 'stop' la categoria de stopword por la que voy a realizar el filtro\n",
        "stop=stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxbeEFDF-ewr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filtro(text_vector):\n",
        "  text_vector_filtrado = []\n",
        "  for palabra in text_vector:\n",
        "    if palabra not in stop:\n",
        "      text_vector_filtrado.append(palabra)\n",
        "  return(text_vector_filtrado)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Bb1hKl-g5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tokens filtrados por stopwords en inglés\n",
        "df_train['text_vector_filtrado']=df_train['text_vector'].apply(filtro)\n",
        "df_train['text_vector_filtrado'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTu988Jx-npG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Asigno en una nueva columna el largo del vector 'text_vector'\n",
        "df_train['elem_vector']=df_train['text_vector'].str.len()\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c87bJqvu-g4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cuento los elementos del vector filtrado 'text_vector_filtrado'\n",
        "df_train['elem_vector_filtrado']=df_train['text_vector_filtrado'].str.len()\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc78PyD7-gvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verifico estructura del DF\n",
        "df_train.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7syMKRb_wVt",
        "colab_type": "text"
      },
      "source": [
        "### Preproceso y categorización de la variable ***Keyword***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fauKBQRp_p0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \"Limpiamos\" la serie de caracteres especiales\n",
        "df_train['keyword']=df_train['keyword'].str.replace('%20','_')\n",
        "# Verificamos actualización\n",
        "df_train['keyword'].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d5T6PLZAFRi",
        "colab_type": "text"
      },
      "source": [
        "### Generación de **diccionario**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-UOXjE7-gtO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Listo para generar un diccionario y traducir la serie 'keyword'\n",
        "keyword_list=df_train['keyword'].unique().tolist()\n",
        "print(keyword_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Fw1BZi-gfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1 Genero lista en espaniol\n",
        "keyword_list_esp=['sin_keyword','en llamas','accidente','replica','accidente_avion','ambulancia','aniquilado','aniquilacion','apocalipse','armageddon','ejercito','incendio_intencional','piromano','ataque','atacado','avalancha','combate/batalla/lucha','bioterror','bioterrorismo','resplandecer/arder','resplandeciente/ardiente','hemorragia','exploto','plaga','ventisca','sangre','sangriento','estallido','bolsa_de_cadaver','embolsado_de_cadaver','bolsas_de_cadaver','bomba','bombardeado','bombardeo','colapso_de_puente','incendio_de_edificios','edificios_en_llamas','quemado','quemando/incendiando','incendio_edificios','incendio_de_matorrales/arbustos','bajas/muertes/perdidas','baja/muerte/perdida','catastrofe','catastrofico','emergencia_quimica','caida_acantilado','colapso','colapsado','colisionar','colisiono','colision','choque','estrellado','aplastamiento','aplastado','toque_de_queda','ciclon','da¤o','peligro','muerto','muerte','muertes','escombros','diluvio','inundado','demoler','demolido','demolicion','descarrilar','descarrilado','descarrilamiento','desolado','desolacion','destruir','destruido','destruccion','detonado','detonacion','devastado','devastacion','desastre','dislacado/desplazado','sequia','ahogar','ahogado','ahogamiento/ahogandose','tormenta_polvo','terremoto','electrocutar','electrocutado','emergencia','plan_de_emergencia','servicio_de_emergencia','engullido','epicentro','evacuar','evacuado','evacuacion','explotar','exploto/detonado/estallado','explosion','testigo_ocular','hambruna','fatal','fatalidades','fatalidades','miedo','fuego','camion_bombero','primeros_en_responder','llamas','aplastado','inundacion','inundaciones','inundaciones','incendio_forestal','incendio_forestales','granizo','tormenta_granizo','da¤o','peligro','peligroso','ola_de_calor','infierno','secuestro','secuestrador','secuestro','rehen','rehenes','huracan','herido/lesionado','heridas/lesiones','herida/lesion','inundado','inundacion','deslisamiento_tierra','lava','rayo','golpe_fuerte/estampido_fuerte','asesinato_en_serie','asesino_en_serie','masacre','caos','fusion','militar','alud_de_lodo','desastre_natural','desastre_nuclear','reactor_nuclear','obliterar/destruir/eliminar','borrado/destruido/eliminado','obliteracion/destruccion/eliminacion','derrame_de_petroleo','brote','pandemonio/confusion/caos','panico','tener_panico','polic¡a','cuarentena','en_cuarentena','emergencia_radiacion','tormenta','arrasado','refugiados','rescate','rescatado','rescatadores','disturbio','disturbios','escombros','ruina','tormenta_de_arena','grito','gritando','gritos','sismico','sumidero/pozo','hundiendose','sirena','sirenas','humo','tormenta_de_nieve','tormenta','camilla','fallo_estructural','bomba_suicida','suicida','bombardeo_suicida','hundido','sobrevivir','sobrevivio','sobreviviente','terrorismo','terrorista','amenaza','trueno','tormenta_electrica','tornado','tragedia','atrapado','trauma','traumatizado','problema','tsunami','tornado/torbellino','tifon','transtorno','tormenta_violenta','volcan','zona_de_guerra','arma','armas','torbellino','incendios_forestales','incendio_forestal','tormenta_de_viento','moretoneado','moretones','naufragio','restos','naufrago']\n",
        "print(keyword_list_esp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNCgM0ujAbQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1 Genero el diccionario eng-esp de la serie 'Keyword'\n",
        "keyword_dicc={}\n",
        "y=0\n",
        "for x in keyword_list:\n",
        "  keyword_dicc[x]=keyword_list_esp[y]\n",
        "  y=y+1\n",
        "  #print(keyword_dicc)\n",
        "\n",
        "print(keyword_dicc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy710P3cAcm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapeo los valores de las key del diccionario keyword_dicc\n",
        "df_train['keyword_esp']=df_train['keyword'].map(keyword_dicc)\n",
        "df_train.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4eq5g2DAmer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verifico el top 20 de las categorias mas frecuentes para la serie keyword \n",
        "df_train['keyword_esp'].value_counts().sort_values(ascending=False).head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjrZqb4GBDoq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hacemos un groupby de las categorias keyword con tweets verdaderos y falsos ('target')\n",
        "df_agrupado=df_train.groupby(['keyword_esp','tweet_type']).size().sort_values(ascending=False)\n",
        "df_agrupado"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWlCzSs4BhhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Otro groupby de la categorias contando ocurrencias de tweets y de caracteres que los conforman\n",
        "df_agrupado_ocurrencias=df_train.groupby(['keyword_esp']).agg({'target':['count'],'caracteres_tweet':['max','min','mean']})\n",
        "df_agrupado_ocurrencias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0oOKHEmChGy",
        "colab_type": "text"
      },
      "source": [
        "### → **Scikit Learn**: Ejecución de **One Hot Encoding** para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1-A_g81CfzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dummifico las categorías\n",
        "df_train_dummies=pd.get_dummies(df_train.keyword)\n",
        "df_train_dummies.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mCZu5xtCXs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hago un join con df_train y df_train_dummies\n",
        "df_train_merged = pd.concat([df_train,df_train_dummies],axis='columns')\n",
        "df_train_merged.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv2OhxtVCXnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Elimino las columnas 'keyword_esp' y 'sin keyword'\n",
        "df_train_merged_final=df_train_merged.drop(['keyword_esp','sin keyword'],axis='columns')\n",
        "df_train_merged_final.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ldMLTArQXJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporto a .csv para verificar estructura\n",
        "df_train_merged_final.to_csv('columna_texto_vector_filtrado.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eifuTrzTXWEM",
        "colab_type": "text"
      },
      "source": [
        "Vectorizo con el feature **CountVectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxJ3npiuXWnn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count_vector=CountVectorizer(\n",
        "    tokenizer = tokenize,\n",
        "    binary = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3MeGM5vXcr2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#count_vector.fit(documents)\n",
        "#vector = count_vector.transform(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_5m6beYeKCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#documents=df_train_merged_final['text_vector_filtrado']\n",
        "#documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzEwex5DeKAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_traincv=cv.fit_transform(df_train_merged_final[['text']])\n",
        "#count_vector.fit(documents)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LLxeuULeJ9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Estoy teniendo problemas al querer pasar 'text_vector_filtrado' como raw document\n",
        "# → Ver variable 'd'\n",
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "#ohe=OneHotEncoder(sparse=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrpgU79VeJ71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ohe.fit_transform(df_train_merged_final['text_vector_filtrado'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBA8hp99eh53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=df_train_merged_final['text_vector_filtrado'].array\n",
        "d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWhDXqoRehu5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#documentos=d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ttWjxQMeJ5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x_traincv=cv.fit_transform([d])\n",
        "#count_vector.fit(d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF8wpOkteJ3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrSEbrReeJsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJpBEHV3eJXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99l0OhhxWqTU",
        "colab_type": "text"
      },
      "source": [
        "### → **Regresion Lineal**: Preproceso **dataframe 'X'** para clasificar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjZweocrco67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "LR_model = LinearRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "radipfxUVRaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dejo solamente el merge con las columnas que me interesan para correr un modelo del Regresion Lineal\n",
        "X=df_train_merged_final.drop(df_train_merged_final.columns[[0,1,2,4,5,6,7,8]], axis='columns')\n",
        "X.head(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeWd9nfCVUhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exporto a .csv para verificar estructura\n",
        "#X.to_excel('X_dummy.xlsx')\n",
        "X.to_csv('X_dummy.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tY7rKYkhCXVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=df_train_merged_final.target\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHl-1aKfc74H",
        "colab_type": "text"
      },
      "source": [
        "#### Verifico el modelo de regresión lineal con las variables X,y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af85PEPic9df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR_model.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o8O8J2hdMhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LR_model.predict([[1,0,0]]) #--> ver error en los parametros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0EZJE_kdNTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ver modelo de scoring\n",
        "LR_model.score(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}